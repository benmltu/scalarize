#!/usr/bin/env python3

r"""
Some data for the experiments.
"""

import torch
from torch import Tensor


tkwargs = {"dtype": torch.double, "device": torch.device("cpu")}

# normalized(pf)[:, 0] > normalized(pf)[:, 1]
ROCKET_PF_DIV_0_GREAT_1 = torch.tensor(
    [
        [-0.4017, -0.5198, 0.1805],
        [-0.3437, -0.4930, 0.1488],
        [-0.3347, -0.4464, 0.0468],
        [-0.3298, -0.4136, -0.0652],
        [-0.3261, -0.4920, 0.0896],
        [-0.3220, -0.4034, -0.1102],
        [-0.3183, -0.4930, 0.0787],
        [-0.3162, -0.4910, 0.0294],
        [-0.3136, -0.4944, 0.0411],
        [-0.3104, -0.5044, 0.0533],
        [-0.3078, -0.4527, -0.0589],
        [-0.3062, -0.4526, -0.0678],
        [-0.3042, -0.4994, -0.0224],
        [-0.3020, -0.5888, 0.1567],
        [-0.3000, -0.5898, 0.1516],
        [-0.2986, -0.5198, -0.0119],
        [-0.2971, -0.5567, 0.0523],
        [-0.2955, -0.5708, 0.0904],
        [-0.2939, -0.6461, 0.2329],
        [-0.2925, -0.5859, 0.1079],
        [-0.2906, -0.6919, 0.2605],
        [-0.2893, -0.4052, -0.1819],
        [-0.2869, -0.7140, 0.2442],
        [-0.2856, -0.6285, 0.1337],
        [-0.2837, -0.7175, 0.1991],
        [-0.2823, -0.6683, 0.1432],
        [-0.2808, -0.3711, -0.3077],
        [-0.2793, -0.5026, -0.0963],
        [-0.2773, -0.7243, 0.1522],
        [-0.2747, -0.5879, 0.0059],
        [-0.2725, -0.3724, -0.3413],
        [-0.2708, -0.6603, 0.0649],
        [-0.2686, -0.6697, 0.0548],
        [-0.2658, -0.3775, -0.3508],
        [-0.2633, -0.4249, -0.2427],
        [-0.2609, -0.6821, 0.0228],
        [-0.2578, -0.5716, -0.0883],
        [-0.2559, -0.6866, 0.0014],
        [-0.2531, -0.6284, -0.0314],
        [-0.2488, -0.3915, -0.3082],
        [-0.2465, -0.8224, 0.0247],
        [-0.2436, -0.5048, -0.1929],
        [-0.2410, -0.6303, -0.0857],
        [-0.2382, -0.3906, -0.4090],
        [-0.2357, -0.6775, -0.0618],
        [-0.2327, -0.5168, -0.2222],
        [-0.2291, -0.6517, -0.1329],
        [-0.2264, -0.7173, -0.0785],
        [-0.2229, -0.8364, -0.0591],
        [-0.2189, -0.7072, -0.1091],
        [-0.2160, -0.6095, -0.1997],
        [-0.2131, -0.7612, -0.1145],
        [-0.2098, -0.8065, -0.1240],
        [-0.2071, -0.4831, -0.2906],
        [-0.2037, -0.4212, -0.3723],
        [-0.2002, -0.6257, -0.2049],
        [-0.1963, -0.9002, -0.1295],
        [-0.1925, -0.7618, -0.1788],
        [-0.1881, -0.5114, -0.3106],
        [-0.1842, -0.4227, -0.4299],
        [-0.1805, -0.4733, -0.3670],
        [-0.1765, -0.5897, -0.2910],
        [-0.1722, -0.4517, -0.4033],
        [-0.1675, -0.4293, -0.4411],
        [-0.1630, -0.6319, -0.3029],
        [-0.1584, -0.5261, -0.3708],
        [-0.1546, -0.4778, -0.4167],
        [-0.1504, -0.8293, -0.2559],
        [-0.1459, -0.6469, -0.3385],
        [-0.1400, -0.5447, -0.3941],
        [-0.1353, -0.5365, -0.4019],
        [-0.1300, -0.5946, -0.3786],
        [-0.1255, -0.5900, -0.3923],
        [-0.1212, -0.9016, -0.3101],
        [-0.1166, -0.7110, -0.3596],
        [-0.1123, -0.5084, -0.4581],
        [-0.1076, -0.4909, -0.4759],
        [-0.1030, -0.5159, -0.4676],
        [-0.0985, -0.6835, -0.4053],
        [-0.0914, -0.4795, -0.6412],
        [-0.0873, -0.4954, -0.5558],
        [-0.0837, -0.5704, -0.4767],
        [-0.0789, -0.8116, -0.3972],
        [-0.0751, -0.6688, -0.4415],
        [-0.0708, -0.5674, -0.6235],
        [-0.0658, -0.5233, -0.8471],
        [-0.0622, -0.5943, -0.6407],
        [-0.0590, -0.7540, -0.4602],
        [-0.0554, -0.5225, -1.0070],
        [-0.0525, -0.6146, -0.8518],
        [-0.0492, -0.6117, -0.8669],
        [-0.0469, -0.5717, -1.0075],
        [-0.0438, -0.9089, -0.6130],
        [-0.0412, -0.7431, -0.6836],
        [-0.0377, -0.6521, -0.9170],
        [-0.0336, -0.6184, -1.0547],
        [-0.0287, -0.8564, -0.8542],
        [-0.0245, -0.7474, -1.0031],
        [-0.0192, -0.7597, -1.0297],
        [-0.0114, -0.8658, -1.0061],
    ],
    **tkwargs
)

# normalized(pf)[:, 1] >= normalized(pf)[:, 0]
ROCKET_PF_DIV_1_GREAT_0 = torch.tensor(
    [
        [-0.9982, -0.0080, -0.0435],
        [-0.9580, -0.0435, -0.0500],
        [-0.9442, -0.0759, -0.0386],
        [-0.9353, -0.1233, -0.0072],
        [-0.9258, -0.0211, -0.1942],
        [-0.9172, -0.0266, -0.2452],
        [-0.9080, -0.0271, -0.4656],
        [-0.9008, -0.1700, 0.0295],
        [-0.8947, -0.0705, -0.0818],
        [-0.8884, -0.0436, -0.2106],
        [-0.8819, -0.0729, -0.0947],
        [-0.8761, -0.0502, -0.2087],
        [-0.8694, -0.1177, -0.0523],
        [-0.8633, -0.0549, -0.2255],
        [-0.8574, -0.1285, -0.0648],
        [-0.8512, -0.0826, -0.1322],
        [-0.8447, -0.1673, -0.0248],
        [-0.8384, -0.0754, -0.2093],
        [-0.8338, -0.0643, -0.4222],
        [-0.8281, -0.0666, -0.4718],
        [-0.8228, -0.0719, -0.3751],
        [-0.8183, -0.0905, -0.2060],
        [-0.8127, -0.0766, -0.3648],
        [-0.8075, -0.0804, -0.3621],
        [-0.8033, -0.0822, -0.3653],
        [-0.7978, -0.1623, -0.0570],
        [-0.7929, -0.1004, -0.2312],
        [-0.7888, -0.1869, -0.0536],
        [-0.7837, -0.2282, -0.0020],
        [-0.7789, -0.2152, -0.0233],
        [-0.7746, -0.1714, -0.0745],
        [-0.7700, -0.1012, -0.3782],
        [-0.7644, -0.1317, -0.1608],
        [-0.7597, -0.1047, -0.6035],
        [-0.7557, -0.1074, -0.5335],
        [-0.7512, -0.2013, -0.0531],
        [-0.7475, -0.1174, -0.2748],
        [-0.7426, -0.1189, -0.3174],
        [-0.7373, -0.1729, -0.0897],
        [-0.7333, -0.1212, -0.5019],
        [-0.7287, -0.2561, -0.0246],
        [-0.7235, -0.1264, -0.6182],
        [-0.7186, -0.1363, -0.2675],
        [-0.7137, -0.1359, -0.2696],
        [-0.7074, -0.1591, -0.1568],
        [-0.7033, -0.1379, -0.6163],
        [-0.6983, -0.1646, -0.1788],
        [-0.6922, -0.1461, -0.3576],
        [-0.6870, -0.1503, -0.3163],
        [-0.6812, -0.1925, -0.1000],
        [-0.6769, -0.2474, -0.0599],
        [-0.6708, -0.1832, -0.1579],
        [-0.6656, -0.1768, -0.2051],
        [-0.6605, -0.3758, 0.0684],
        [-0.6553, -0.1660, -0.5162],
        [-0.6506, -0.1717, -0.2909],
        [-0.6451, -0.3494, 0.0297],
        [-0.6403, -0.1749, -0.3796],
        [-0.6346, -0.2189, -0.1061],
        [-0.6289, -0.1847, -0.2742],
        [-0.6232, -0.2981, -0.0160],
        [-0.6169, -0.1883, -0.4651],
        [-0.6110, -0.1917, -0.3694],
        [-0.6040, -0.1983, -0.2740],
        [-0.5967, -0.1994, -0.3696],
        [-0.5893, -0.2040, -0.4208],
        [-0.5827, -0.2241, -0.2004],
        [-0.5769, -0.2355, -0.1675],
        [-0.5717, -0.2146, -0.3499],
        [-0.5643, -0.2481, -0.1168],
        [-0.5574, -0.2597, -0.1054],
        [-0.5517, -0.2687, -0.0831],
        [-0.5436, -0.2602, -0.1122],
        [-0.5367, -0.3071, -0.0423],
        [-0.5287, -0.2515, -0.2084],
        [-0.5226, -0.2926, -0.0748],
        [-0.5157, -0.2520, -0.2513],
        [-0.5060, -0.4954, 0.1506],
        [-0.4957, -0.3345, -0.0177],
        [-0.4885, -0.2781, -0.1519],
        [-0.4811, -0.2813, -0.1736],
        [-0.4728, -0.3068, -0.0848],
        [-0.4656, -0.2736, -0.3273],
        [-0.4579, -0.2794, -0.2606],
        [-0.4475, -0.3373, -0.0426],
        [-0.4394, -0.2906, -0.2672],
        [-0.4290, -0.2946, -0.2700],
        [-0.4186, -0.4085, 0.0421],
        [-0.4078, -0.3185, -0.1814],
        [-0.3974, -0.3273, -0.1482],
        [-0.3870, -0.4109, 0.0505],
        [-0.3778, -0.4173, 0.0410],
        [-0.3683, -0.3819, -0.0159],
        [-0.3619, -0.3339, -0.2308],
        [-0.3554, -0.3966, -0.0236],
        [-0.3492, -0.3348, -0.2981],
        [-0.3418, -0.3385, -0.3100],
        [-0.3319, -0.3673, -0.1378],
        [-0.3182, -0.3497, -0.3850],
        [-0.2938, -0.3616, -0.2651],
    ],
    **tkwargs
)

# normalized(pf)[:, 0] > normalized(pf)[:, 2]
VEHICLE_PF_DIV_0_GREAT_2 = torch.tensor(
    [
        [-1.6626e03, -8.0331e00, -9.0555e-02],
        [-1.6628e03, -7.9874e00, -9.3126e-02],
        [-1.6629e03, -7.9420e00, -9.5464e-02],
        [-1.6631e03, -7.8840e00, -9.8137e-02],
        [-1.6633e03, -7.8389e00, -9.9973e-02],
        [-1.6635e03, -7.7781e00, -1.0211e-01],
        [-1.6644e03, -7.7087e00, -1.0326e-01],
        [-1.6645e03, -7.6666e00, -1.0419e-01],
        [-1.6642e03, -7.5830e00, -1.0638e-01],
        [-1.6643e03, -7.5353e00, -1.0682e-01],
        [-1.6645e03, -7.4731e00, -1.0703e-01],
        [-1.6648e03, -7.4076e00, -1.0682e-01],
        [-1.6650e03, -7.3490e00, -1.0626e-01],
        [-1.6651e03, -7.3040e00, -1.0558e-01],
        [-1.6653e03, -7.2650e00, -1.0482e-01],
        [-1.6654e03, -7.2306e00, -1.0402e-01],
        [-1.6655e03, -7.2052e00, -1.0335e-01],
        [-1.6656e03, -7.1791e00, -1.0259e-01],
        [-1.6705e03, -6.9189e00, -1.7105e-01],
        [-1.6708e03, -6.9007e00, -1.7538e-01],
        [-1.6785e03, -6.8878e00, -1.7409e-01],
        [-1.6710e03, -6.8764e00, -1.8062e-01],
        [-1.6799e03, -6.8635e00, -1.7515e-01],
        [-1.6713e03, -6.8532e00, -1.8517e-01],
        [-1.6714e03, -6.8409e00, -1.8743e-01],
        [-1.6783e03, -6.8253e00, -1.8283e-01],
        [-1.6793e03, -6.8133e00, -1.8264e-01],
        [-1.6819e03, -6.8081e00, -1.7781e-01],
        [-1.6802e03, -6.8015e00, -1.8226e-01],
        [-1.6718e03, -6.7933e00, -1.9548e-01],
        [-1.6783e03, -6.7869e00, -1.8764e-01],
        [-1.6720e03, -6.7781e00, -1.9786e-01],
        [-1.6821e03, -6.7716e00, -1.8131e-01],
        [-1.6721e03, -6.7636e00, -2.0005e-01],
        [-1.6721e03, -6.7583e00, -2.0084e-01],
        [-1.6745e03, -6.7535e00, -1.9854e-01],
        [-1.6722e03, -6.7472e00, -2.0246e-01],
        [-1.6764e03, -6.7391e00, -1.9728e-01],
        [-1.6804e03, -6.7323e00, -1.8980e-01],
        [-1.6800e03, -6.7256e00, -1.9146e-01],
        [-1.6733e03, -6.7192e00, -2.0510e-01],
        [-1.6725e03, -6.7120e00, -2.0736e-01],
        [-1.6790e03, -6.7060e00, -1.9584e-01],
        [-1.6726e03, -6.7003e00, -2.0893e-01],
        [-1.6726e03, -6.6926e00, -2.0994e-01],
        [-1.6797e03, -6.6864e00, -1.9651e-01],
        [-1.6823e03, -6.6804e00, -1.9159e-01],
        [-1.6827e03, -6.6726e00, -1.9005e-01],
        [-1.6803e03, -6.6667e00, -1.9723e-01],
        [-1.6775e03, -6.6588e00, -2.0479e-01],
        [-1.6797e03, -6.6511e00, -2.0026e-01],
        [-1.6811e03, -6.6430e00, -1.9744e-01],
        [-1.6817e03, -6.6376e00, -1.9640e-01],
        [-1.6732e03, -6.6328e00, -2.1703e-01],
        [-1.6815e03, -6.6258e00, -1.9822e-01],
        [-1.6830e03, -6.6183e00, -1.9448e-01],
        [-1.6732e03, -6.6100e00, -2.2012e-01],
        [-1.6831e03, -6.6009e00, -1.9586e-01],
        [-1.6771e03, -6.5924e00, -2.1325e-01],
        [-1.6805e03, -6.5853e00, -2.0511e-01],
        [-1.6733e03, -6.5774e00, -2.2383e-01],
        [-1.6734e03, -6.5700e00, -2.2466e-01],
        [-1.6789e03, -6.5624e00, -2.1188e-01],
        [-1.6803e03, -6.5552e00, -2.0866e-01],
        [-1.6736e03, -6.5479e00, -2.2681e-01],
        [-1.6736e03, -6.5398e00, -2.2795e-01],
        [-1.6736e03, -6.5288e00, -2.2913e-01],
        [-1.6823e03, -6.5210e00, -2.0564e-01],
        [-1.6795e03, -6.5135e00, -2.1510e-01],
        [-1.6796e03, -6.5066e00, -2.1542e-01],
        [-1.6786e03, -6.4996e00, -2.1921e-01],
        [-1.6769e03, -6.4926e00, -2.2481e-01],
        [-1.6745e03, -6.4824e00, -2.3238e-01],
        [-1.6806e03, -6.4741e00, -2.1546e-01],
        [-1.6804e03, -6.4654e00, -2.1712e-01],
        [-1.6773e03, -6.4559e00, -2.2730e-01],
        [-1.6838e03, -6.4480e00, -2.0712e-01],
        [-1.6801e03, -6.4400e00, -2.2049e-01],
        [-1.6832e03, -6.4324e00, -2.1068e-01],
        [-1.6765e03, -6.4261e00, -2.3299e-01],
        [-1.6840e03, -6.4183e00, -2.0918e-01],
        [-1.6782e03, -6.4117e00, -2.2909e-01],
        [-1.6774e03, -6.4017e00, -2.3255e-01],
        [-1.6828e03, -6.3919e00, -2.1562e-01],
        [-1.6841e03, -6.3808e00, -2.1170e-01],
        [-1.6780e03, -6.3714e00, -2.3355e-01],
        [-1.6756e03, -6.3631e00, -2.4205e-01],
        [-1.6787e03, -6.3540e00, -2.3312e-01],
        [-1.6791e03, -6.3429e00, -2.3277e-01],
        [-1.6843e03, -6.3335e00, -2.1481e-01],
        [-1.6753e03, -6.3218e00, -2.4718e-01],
        [-1.6747e03, -6.3123e00, -2.4993e-01],
        [-1.6748e03, -6.3010e00, -2.5091e-01],
        [-1.6833e03, -6.2940e00, -2.2184e-01],
        [-1.6825e03, -6.2788e00, -2.2609e-01],
        [-1.6755e03, -6.2629e00, -2.5260e-01],
        [-1.6810e03, -6.2492e00, -2.3434e-01],
        [-1.6796e03, -6.2231e00, -2.4161e-01],
        [-1.6760e03, -6.1939e00, -2.5728e-01],
        [-1.6755e03, -6.1428e00, -2.6400e-01],
    ],
    **tkwargs
)

# normalized(pf)[:, 2] >= normalized(pf)[:, 0]
VEHICLE_PF_DIV_2_GREAT_0 = torch.tensor(
    [
        [-1.6952e03, -1.0745e01, -3.9400e-02],
        [-1.6899e03, -1.0094e01, -4.3342e-02],
        [-1.6884e03, -9.8043e00, -4.4821e-02],
        [-1.6873e03, -9.6432e00, -4.6515e-02],
        [-1.6873e03, -9.5796e00, -4.6538e-02],
        [-1.6859e03, -9.5316e00, -4.8781e-02],
        [-1.6869e03, -9.4944e00, -4.7331e-02],
        [-1.6841e03, -9.4641e00, -5.1789e-02],
        [-1.6856e03, -9.4291e00, -4.9346e-02],
        [-1.6854e03, -9.3685e00, -4.9794e-02],
        [-1.6858e03, -9.2909e00, -4.9569e-02],
        [-1.6851e03, -9.1637e00, -5.1232e-02],
        [-1.6737e03, -8.9716e00, -5.2392e-02],
        [-1.6732e03, -8.8951e00, -5.2534e-02],
        [-1.6728e03, -8.8264e00, -5.2727e-02],
        [-1.6722e03, -8.7260e00, -5.3129e-02],
        [-1.6718e03, -8.6692e00, -5.3423e-02],
        [-1.6708e03, -8.5112e00, -5.4508e-02],
        [-1.6698e03, -8.4613e00, -5.6237e-02],
        [-1.6691e03, -8.4468e00, -5.7589e-02],
        [-1.6683e03, -8.4322e00, -5.8946e-02],
        [-1.6699e03, -8.4181e00, -5.9904e-02],
        [-1.6670e03, -8.4076e00, -6.1227e-02],
        [-1.6665e03, -8.3978e00, -6.2144e-02],
        [-1.6661e03, -8.3898e00, -6.2883e-02],
        [-1.6656e03, -8.3807e00, -6.3733e-02],
        [-1.6651e03, -8.3713e00, -6.4628e-02],
        [-1.6647e03, -8.3623e00, -6.5435e-02],
        [-1.6642e03, -8.3534e00, -6.6263e-02],
        [-1.6637e03, -8.3438e00, -6.7161e-02],
        [-1.6632e03, -8.3337e00, -6.8094e-02],
        [-1.6627e03, -8.3234e00, -6.9055e-02],
        [-1.6621e03, -8.3130e00, -7.0024e-02],
        [-1.6661e03, -8.2958e00, -7.0685e-02],
        [-1.6797e03, -8.2660e00, -6.0720e-02],
        [-1.6658e03, -8.2417e00, -7.4928e-02],
        [-1.6620e03, -8.2206e00, -7.7736e-02],
        [-1.6632e03, -8.2067e00, -7.8464e-02],
        [-1.6640e03, -8.1855e00, -7.9712e-02],
        [-1.6622e03, -8.1685e00, -8.1667e-02],
        [-1.6678e03, -8.1469e00, -8.0409e-02],
        [-1.6624e03, -8.1315e00, -8.4246e-02],
        [-1.6624e03, -8.1110e00, -8.5673e-02],
        [-1.6624e03, -8.0951e00, -8.6721e-02],
        [-1.6625e03, -8.0712e00, -8.8249e-02],
        [-1.6626e03, -8.0508e00, -8.9503e-02],
        [-1.6788e03, -8.0350e00, -6.3232e-02],
        [-1.6739e03, -8.0048e00, -7.2028e-02],
        [-1.6730e03, -7.9695e00, -7.3497e-02],
        [-1.6651e03, -7.9297e00, -9.4230e-02],
        [-1.6706e03, -7.8905e00, -7.7866e-02],
        [-1.6782e03, -7.8624e00, -6.5319e-02],
        [-1.6734e03, -7.8371e00, -7.3546e-02],
        [-1.6702e03, -7.8034e00, -7.9061e-02],
        [-1.6696e03, -7.7749e00, -8.0272e-02],
        [-1.6750e03, -7.7437e00, -7.1724e-02],
        [-1.6717e03, -7.7181e00, -7.7101e-02],
        [-1.6727e03, -7.6845e00, -7.5672e-02],
        [-1.6774e03, -7.6473e00, -6.8182e-02],
        [-1.6765e03, -7.6253e00, -6.9994e-02],
        [-1.6772e03, -7.5940e00, -6.8939e-02],
        [-1.6725e03, -7.5736e00, -7.6748e-02],
        [-1.6729e03, -7.5432e00, -7.6244e-02],
        [-1.6769e03, -7.5235e00, -6.9970e-02],
        [-1.6685e03, -7.4990e00, -8.3850e-02],
        [-1.6716e03, -7.4778e00, -7.8964e-02],
        [-1.6744e03, -7.4583e00, -7.4492e-02],
        [-1.6706e03, -7.4389e00, -8.0921e-02],
        [-1.6765e03, -7.4194e00, -7.1554e-02],
        [-1.6762e03, -7.3956e00, -7.2138e-02],
        [-1.6763e03, -7.3758e00, -7.2240e-02],
        [-1.6716e03, -7.3578e00, -7.9956e-02],
        [-1.6761e03, -7.3363e00, -7.2874e-02],
        [-1.6701e03, -7.3114e00, -8.2865e-02],
        [-1.6677e03, -7.2917e00, -8.6869e-02],
        [-1.6692e03, -7.2690e00, -8.4712e-02],
        [-1.6738e03, -7.2435e00, -7.7498e-02],
        [-1.6680e03, -7.2175e00, -8.7132e-02],
        [-1.6674e03, -7.1966e00, -8.8352e-02],
        [-1.6688e03, -7.1725e00, -8.6256e-02],
        [-1.6683e03, -7.1565e00, -8.7217e-02],
        [-1.6709e03, -7.1416e00, -8.3227e-02],
        [-1.6657e03, -7.1241e00, -1.0076e-01],
        [-1.6750e03, -7.1119e00, -7.7076e-02],
        [-1.6746e03, -7.1036e00, -7.7848e-02],
        [-1.6658e03, -7.0935e00, -9.9606e-02],
        [-1.6734e03, -7.0814e00, -7.9912e-02],
        [-1.6659e03, -7.0691e00, -9.8614e-02],
        [-1.6722e03, -7.0571e00, -8.2165e-02],
        [-1.6660e03, -7.0464e00, -9.7637e-02],
        [-1.6677e03, -7.0370e00, -8.9385e-02],
        [-1.6706e03, -7.0265e00, -8.5009e-02],
        [-1.6701e03, -7.0167e00, -8.5918e-02],
        [-1.6698e03, -7.0107e00, -8.6480e-02],
        [-1.6693e03, -7.0014e00, -8.7344e-02],
        [-1.6689e03, -6.9943e00, -8.7996e-02],
        [-1.6684e03, -6.9834e00, -8.9012e-02],
        [-1.6680e03, -6.9758e00, -8.9715e-02],
        [-1.6672e03, -6.9603e00, -9.1161e-02],
        [-1.6810e03, -6.9362e00, -1.6394e-01],
    ],
    **tkwargs
)

# normalized(pf)[:, 0] > normalized(pf)[:, 1]
ZDT3_PF_DIV_0_GREAT_1 = torch.tensor(
    [
        [-4.3059e-01, 9.1802e-03],
        [-4.2947e-01, -1.4598e-03],
        [-4.2835e-01, -1.2478e-02],
        [-4.2723e-01, -2.3860e-02],
        [-4.2611e-01, -3.5591e-02],
        [-4.2499e-01, -4.7654e-02],
        [-4.2387e-01, -6.0035e-02],
        [-4.2275e-01, -7.2717e-02],
        [-4.2163e-01, -8.5683e-02],
        [-4.2051e-01, -9.8917e-02],
        [-4.1939e-01, -1.1240e-01],
        [-4.1827e-01, -1.2612e-01],
        [-4.1715e-01, -1.4005e-01],
        [-4.1603e-01, -1.5419e-01],
        [-4.1491e-01, -1.6850e-01],
        [-4.1379e-01, -1.8298e-01],
        [-4.1267e-01, -1.9760e-01],
        [-4.1155e-01, -2.1235e-01],
        [-4.1043e-01, -2.2720e-01],
        [-4.0931e-01, -2.4215e-01],
        [-2.5624e-01, -2.4247e-01],
        [-2.5435e-01, -2.4369e-01],
        [-2.5245e-01, -2.4586e-01],
        [-2.5055e-01, -2.4894e-01],
        [-2.4865e-01, -2.5292e-01],
        [-2.4675e-01, -2.5778e-01],
        [-2.4486e-01, -2.6350e-01],
        [-2.4296e-01, -2.7005e-01],
        [-2.4106e-01, -2.7740e-01],
        [-2.3916e-01, -2.8552e-01],
        [-2.3727e-01, -2.9437e-01],
        [-2.3537e-01, -3.0392e-01],
        [-2.3347e-01, -3.1412e-01],
        [-2.3157e-01, -3.2494e-01],
        [-2.2967e-01, -3.3634e-01],
        [-2.2778e-01, -3.4826e-01],
        [-2.2588e-01, -3.6067e-01],
        [-2.2398e-01, -3.7351e-01],
        [-2.2208e-01, -3.8674e-01],
        [-2.2019e-01, -4.0030e-01],
        [-2.1829e-01, -4.1416e-01],
        [-2.1639e-01, -4.2826e-01],
        [-2.1449e-01, -4.4255e-01],
        [-2.1259e-01, -4.5698e-01],
        [-2.1070e-01, -4.7151e-01],
        [-2.0880e-01, -4.8607e-01],
        [-2.0690e-01, -5.0063e-01],
        [-2.0500e-01, -5.1514e-01],
        [-2.0311e-01, -5.2955e-01],
        [-2.0121e-01, -5.4381e-01],
        [-1.9931e-01, -5.5788e-01],
        [-1.9741e-01, -5.7172e-01],
        [-1.9551e-01, -5.8529e-01],
        [-1.9362e-01, -5.9855e-01],
        [-1.9172e-01, -6.1146e-01],
        [-1.8982e-01, -6.2399e-01],
        [-1.8792e-01, -6.3610e-01],
        [-1.8603e-01, -6.4777e-01],
        [-1.8413e-01, -6.5896e-01],
        [-1.8223e-01, -6.6965e-01],
        [-8.1332e-02, -6.6980e-01],
        [-7.9247e-02, -6.7041e-01],
        [-7.7161e-02, -6.7149e-01],
        [-7.5076e-02, -6.7304e-01],
        [-7.2991e-02, -6.7507e-01],
        [-7.0905e-02, -6.7756e-01],
        [-6.8820e-02, -6.8053e-01],
        [-6.6734e-02, -6.8395e-01],
        [-6.4649e-02, -6.8782e-01],
        [-6.2563e-02, -6.9212e-01],
        [-6.0478e-02, -6.9685e-01],
        [-5.8393e-02, -7.0198e-01],
        [-5.6307e-02, -7.0750e-01],
        [-5.4222e-02, -7.1340e-01],
        [-5.2136e-02, -7.1965e-01],
        [-5.0051e-02, -7.2623e-01],
        [-4.7966e-02, -7.3312e-01],
        [-4.5880e-02, -7.4031e-01],
        [-4.3795e-02, -7.4776e-01],
        [-4.1709e-02, -7.5547e-01],
        [-3.9624e-02, -7.6341e-01],
        [-3.7538e-02, -7.7155e-01],
        [-3.5453e-02, -7.7990e-01],
        [-3.3368e-02, -7.8842e-01],
        [-3.1282e-02, -7.9710e-01],
        [-2.9197e-02, -8.0595e-01],
        [-2.7111e-02, -8.1495e-01],
        [-2.5026e-02, -8.2409e-01],
        [-2.2941e-02, -8.3340e-01],
        [-2.0855e-02, -8.4288e-01],
        [-1.8770e-02, -8.5256e-01],
        [-1.6684e-02, -8.6248e-01],
        [-1.4599e-02, -8.7271e-01],
        [-1.2513e-02, -8.8334e-01],
        [-1.0428e-02, -8.9453e-01],
        [-8.3427e-03, -9.0650e-01],
        [-6.2572e-03, -9.1968e-01],
        [-4.1718e-03, -9.3487e-01],
        [-2.0864e-03, -9.5419e-01],
        [-1.0000e-06, -9.9900e-01],
    ],
    **tkwargs
)

# normalized(pf)[:, 1] >= normalized(pf)[:, 0]
ZDT3_PF_DIV_1_GREAT_0 = torch.tensor(
    [
        [-0.8518, 0.7734],
        [-0.8511, 0.7732],
        [-0.8504, 0.7725],
        [-0.8497, 0.7714],
        [-0.8490, 0.7699],
        [-0.8483, 0.7680],
        [-0.8475, 0.7656],
        [-0.8468, 0.7628],
        [-0.8461, 0.7596],
        [-0.8454, 0.7560],
        [-0.8447, 0.7519],
        [-0.8440, 0.7475],
        [-0.8432, 0.7426],
        [-0.8424, 0.7362],
        [-0.8417, 0.7304],
        [-0.8409, 0.7242],
        [-0.8402, 0.7176],
        [-0.8395, 0.7106],
        [-0.8388, 0.7033],
        [-0.8381, 0.6955],
        [-0.8374, 0.6874],
        [-0.8367, 0.6788],
        [-0.8359, 0.6699],
        [-0.8352, 0.6607],
        [-0.8345, 0.6511],
        [-0.8336, 0.6390],
        [-0.8329, 0.6286],
        [-0.8322, 0.6179],
        [-0.8315, 0.6068],
        [-0.8308, 0.5953],
        [-0.8301, 0.5836],
        [-0.8293, 0.5715],
        [-0.8286, 0.5591],
        [-0.8279, 0.5464],
        [-0.8272, 0.5334],
        [-0.8265, 0.5201],
        [-0.8258, 0.5065],
        [-0.8251, 0.4927],
        [-0.8242, 0.4757],
        [-0.8235, 0.4612],
        [-0.6520, 0.4582],
        [-0.6511, 0.4577],
        [-0.6503, 0.4567],
        [-0.6494, 0.4552],
        [-0.6486, 0.4532],
        [-0.6477, 0.4508],
        [-0.6469, 0.4480],
        [-0.6460, 0.4446],
        [-0.6451, 0.4408],
        [-0.6443, 0.4366],
        [-0.6433, 0.4309],
        [-0.6424, 0.4257],
        [-0.6415, 0.4200],
        [-0.6407, 0.4139],
        [-0.6398, 0.4073],
        [-0.6390, 0.4003],
        [-0.6381, 0.3929],
        [-0.6373, 0.3851],
        [-0.6364, 0.3769],
        [-0.6355, 0.3683],
        [-0.6347, 0.3593],
        [-0.6338, 0.3499],
        [-0.6328, 0.3381],
        [-0.6319, 0.3279],
        [-0.6311, 0.3173],
        [-0.6302, 0.3063],
        [-0.6294, 0.2951],
        [-0.6285, 0.2834],
        [-0.6277, 0.2715],
        [-0.6268, 0.2592],
        [-0.6259, 0.2467],
        [-0.6251, 0.2338],
        [-0.6242, 0.2206],
        [-0.6234, 0.2072],
        [-0.6225, 0.1935],
        [-0.6215, 0.1767],
        [-0.6206, 0.1624],
        [-0.6198, 0.1479],
        [-0.6189, 0.1332],
        [-0.4537, 0.1242],
        [-0.4525, 0.1238],
        [-0.4514, 0.1228],
        [-0.4503, 0.1213],
        [-0.4492, 0.1192],
        [-0.4481, 0.1166],
        [-0.4469, 0.1134],
        [-0.4458, 0.1097],
        [-0.4445, 0.1045],
        [-0.4434, 0.0996],
        [-0.4422, 0.0942],
        [-0.4411, 0.0882],
        [-0.4400, 0.0818],
        [-0.4389, 0.0748],
        [-0.4378, 0.0674],
        [-0.4366, 0.0595],
        [-0.4355, 0.0511],
        [-0.4344, 0.0423],
        [-0.4333, 0.0331],
        [-0.4322, 0.0234],
        [-0.4308, 0.0113],
    ],
    **tkwargs
)


def get_rocket_pf(
    upper: bool,
) -> Tensor:
    r"""Returns the 100 reference points for the RocketInjector problem.

    Args:
        upper: Return the upper part of the Pareto front.

    Returns:
        A `100 x M`-dim Tensor containing the reference points.
    """
    if upper:
        return ROCKET_PF_DIV_1_GREAT_0
    else:
        return ROCKET_PF_DIV_0_GREAT_1


def get_vehicle_pf(
    upper: bool,
) -> Tensor:
    r"""Returns the 100 reference points for the VehicleSafety problem.

    Args:
        upper: Return the upper part of the Pareto front.

    Returns:
        A `100 x M`-dim Tensor containing the reference points.
    """
    if upper:
        return VEHICLE_PF_DIV_2_GREAT_0
    else:
        return VEHICLE_PF_DIV_0_GREAT_2


def get_zdt3_pf(
    upper: bool,
) -> Tensor:
    r"""Returns the 100 reference points for the ZDT3 problem.

    Args:
        upper: Return the upper part of the Pareto front.

    Returns:
        A `100 x M`-dim Tensor containing the reference points.
    """
    if upper:
        return ZDT3_PF_DIV_1_GREAT_0
    else:
        return ZDT3_PF_DIV_0_GREAT_1
